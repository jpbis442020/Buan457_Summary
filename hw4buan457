{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d938c63-2649-4b28-b963-81fa5be17f3a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in /Users/Jacques/anaconda3/lib/python3.10/site-packages (0.0.post10)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5da8fbff-6772-426c-afcb-bc6041bf2ed1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'bertopic'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m df\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maib_phishing.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m df\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbertopic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BERTopic\n\u001b[1;32m      8\u001b[0m bt\u001b[38;5;241m=\u001b[39m BERTopic()\n\u001b[1;32m      9\u001b[0m all_text\u001b[38;5;241m=\u001b[39mdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124memails\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto_list()\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'bertopic'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "df=pd.read_csv('aib_phishing.csv')\n",
    "df.shape\n",
    "from bertopic import BERTopic\n",
    "bt= BERTopic()\n",
    "all_text=df['emails'].to_list()\n",
    "topics, probs= bt.fit_transform(all_text)\n",
    "df['topic']=topics\n",
    "df['probs']=probs\n",
    "bt.get_topic_freq().head(10)\n",
    "len(bt.get_topic_freq())\n",
    "# num of topics is 49\n",
    "bt.get_topic_freq()\n",
    "# topic -1 has highest count at 466\n",
    "from sentence_transformers import SentenceTransformer\n",
    "T5=SentenceTransformer('sentence-t5-base')\n",
    "embeddings=T5.encode(df['emails'])\n",
    "df_embed=pd.DataFrame(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dca9c37-957e-4e32-a85e-f6f3cbd37c5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebda0202-db97-407e-b0c6-12f853894c80",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TfidfVectorizer\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecomposition\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PCA\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load your data and target variable\n",
    "X, y = load_data_and_labels()\n",
    "\n",
    "# Step 2: Feature Engineering\n",
    "\n",
    "# a. Tfidf Vectorization\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(X)\n",
    "\n",
    "# b. PCA from Tfidf\n",
    "pca_tfidf = PCA(n_components=10)\n",
    "X_pca_tfidf = pca_tfidf.fit_transform(X_tfidf)\n",
    "\n",
    "# c. Sentence Transformer\n",
    "sentence_transformer = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "X_sentence_transformer = sentence_transformer.encode(X)\n",
    "\n",
    "# d. PCA from Sentence Transformer\n",
    "pca_sentence_transformer = PCA(n_components=10)\n",
    "X_pca_sentence_transformer = pca_sentence_transformer.fit_transform(X_sentence_transformer)\n",
    "\n",
    "# Step 3: Choose and train an algorithm (Logistic Regression in this example)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize and train the algorithm\n",
    "logistic_regression = LogisticRegression()\n",
    "logistic_regression.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = logistic_regression.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926770d0-df57-4a84-b107-f95490a085fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
